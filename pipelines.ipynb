{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from sklearn.metrics.cluster import calinski_harabaz_score, adjusted_rand_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's create 2 pipelines: one for K-Means Clustering, one for Hierarchical Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = None\n",
    "k = None\n",
    "k_max = None # maximum no. of clusters will will evaluate\n",
    "\n",
    "pipe_kmeans = Pipeline([('scl', StandardScaler()),\n",
    "            ('pca', PCA(n_components=c)),  # change value of c for # of PCA components\n",
    "            ('clf', KMeans(n_clusters=k))]) # value of k changes in loop\n",
    "\n",
    "pipe_HAC = Pipeline([('scl', StandardScaler()),\n",
    "            ('pca', PCA(n_components=c)), # see above\n",
    "            ('clf', AgglomerativeClustering(n_clusters=k))]) # see above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now let's pass our data through the K-means pipeline, visually graph clusters, and interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def processKmeans(k_max, df):\n",
    "    # fit and predict clusters\n",
    "    for k in range(0, k_max):\n",
    "        pipe_kmeans.fit(df)\n",
    "        cluster_preds = pipe_kmeans.predict(df)\n",
    "        print(f'K-Means Solution with {k} clusters')\n",
    "        print('Calinski-Harabaz (CA) cluster variance score: ', calinski_harabaz_score(df, cluster_preds))\n",
    "        print('\\n')\n",
    "\n",
    "        plt.title(f'K-Means Solution with {k} clusters')\n",
    "        plt.scatter(X.Frequency, X.MonetaryValue, c=cluster_preds, s=10)\n",
    "        cl_centers = pipe_kmeans.cluster_centers_\n",
    "        plt.scatter(cl_centers[:, 0], cl_centers[:, 1], c='black', s=30); # ! check on this centering selection\n",
    "        \n",
    "    # merge cluster predicitons to unlogged, unscaled df and print summary stats by cluster\n",
    "    customer_level_data_raw['Cluster'] = cluster_preds\n",
    "    for cluster in set(cluster_preds):\n",
    "        print(f'Summary Stats for cluster # {cluster}')\n",
    "        customer_level_data_raw[customer_level_data_raw['Cluster'] == cluster].describe()\n",
    "        pop_perc = (len(customer_level_data_raw[customer_level_data_raw['Cluster'] == cluster]) / len(customer_level_data_raw))*100\n",
    "        rev_perc = (sum(customer_level_data_raw[customer_level_data_raw['Cluster'] == cluster].MonetaryValue) / sum(customer_level_data_raw.MonetaryValue))*100               \n",
    "        total_spend = sum(customer_level_data_raw[customer_level_data_raw['Cluster'] == cluster].MonetaryValue)\n",
    "        print(f'This cluster represents {pop_perc}% of the population and {rev_perc}% or Total Revenue, with a total spend of {total_spend}')\n",
    "        print('\\n\\n\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> > Now let's pass our data through the HAC pipeline, visually graph clusters, and interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
